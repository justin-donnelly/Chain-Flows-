{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from pandas import json_normalize\n",
    "import time\n",
    "from defillama import DefiLlama\n",
    "from datetime import datetime\n",
    "llama = DefiLlama()\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import sqlite3\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# flows = 2.5 seconds\n",
    "# stables = half a min to a minute and a half\n",
    "# tvl = 1 second\n",
    "# dex vol = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_net_flows(chain_name: str):\n",
    "    ids = []\n",
    "    aggregated_data = {}\n",
    "    \n",
    "    # Fetch bridge data\n",
    "    bridges_url = \"https://bridges.llama.fi/bridges?includeChains=true\"\n",
    "    bridges_response = requests.get(bridges_url).json()\n",
    "    \n",
    "    # Collect IDs for bridges that involve the specified chain\n",
    "    for bridge in bridges_response['bridges']:\n",
    "        if chain_name in bridge['chains']:\n",
    "            ids.append(bridge['id'])\n",
    "    \n",
    "    # Initialize variables to track the most recent date and its net flows\n",
    "    most_recent_date = None\n",
    "    most_recent_net_flows = 0\n",
    "    \n",
    "    for id in ids:\n",
    "        url = f\"https://bridges.llama.fi/bridgevolume/{chain_name}?id={id}\"\n",
    "        vol_data = requests.get(url).json()[-60:]  # Retrieve the last 60 entries\n",
    "        \n",
    "        for entry in vol_data:\n",
    "            # Convert entry date to a datetime object in 'US/Eastern' timezone\n",
    "            entry_date = datetime.utcfromtimestamp(int(entry['date'])).replace(tzinfo=pytz.utc).astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "            entry_date_str = entry_date.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Update the most recent date and its net flows if this entry is more recent\n",
    "            if most_recent_date is None or entry_date > most_recent_date:\n",
    "                most_recent_date = entry_date\n",
    "                most_recent_net_flows = entry['depositUSD'] - entry['withdrawUSD']\n",
    "            elif entry_date == most_recent_date:\n",
    "                # If the entry date matches the most recent date, aggregate the net flows\n",
    "                most_recent_net_flows += entry['depositUSD'] - entry['withdrawUSD']\n",
    "    \n",
    "    # Return the most recent date and its aggregated net flows\n",
    "    if most_recent_date:\n",
    "        aggregated_data[most_recent_date.strftime('%Y-%m-%d')] = round(most_recent_net_flows,2)\n",
    "    return aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_stables(chain_name: str):\n",
    "    \"\"\"\n",
    "    Fetches the most recent stablecoin total value for the specified chain.\n",
    "    \"\"\"\n",
    "    stable_ids = list(range(1, 161))  # Assuming stablecoin IDs from 1 to 160\n",
    "    most_recent_date = None\n",
    "    most_recent_total_stables = 0\n",
    "    \n",
    "    for id in stable_ids:\n",
    "        url = f\"https://stablecoins.llama.fi/stablecoincharts/{chain_name}?stablecoin={id}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            stables_data = response.json()\n",
    "            if stables_data:\n",
    "                # Assuming the last entry is the most recent\n",
    "                entry = stables_data[-1]\n",
    "                date = datetime.utcfromtimestamp(int(entry['date'])).replace(tzinfo=pytz.utc).astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "                \n",
    "                # Check if this entry's date is the most recent we've encountered\n",
    "                if most_recent_date is None or date > most_recent_date:\n",
    "                    most_recent_date = date\n",
    "                    most_recent_total_stables = entry.get('totalCirculating', {}).get('peggedUSD', 0)\n",
    "                elif date == most_recent_date:\n",
    "                    # If the entry's date matches the most recent date, aggregate the totals\n",
    "                    most_recent_total_stables += entry.get('totalCirculating', {}).get('peggedUSD', 0)\n",
    "    \n",
    "    # Return the most recent date and its aggregated total stablecoin value\n",
    "    if most_recent_date:\n",
    "        return {most_recent_date.strftime('%Y-%m-%d'): most_recent_total_stables}\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_tvl(chain_name: str):\n",
    "    \"\"\"\n",
    "    Fetches the most recent Total Value Locked (TVL) for the specified chain.\n",
    "    \"\"\"\n",
    "    tvl_url = f\"https://api.llama.fi/v2/historicalChainTvl/{chain_name}\"\n",
    "    response = requests.get(tvl_url)\n",
    "    if response.status_code == 200:\n",
    "        tvl_data = response.json()\n",
    "        if tvl_data:\n",
    "            # Assuming the last entry is the most recent\n",
    "            most_recent_entry = tvl_data[-1]\n",
    "            date = datetime.utcfromtimestamp(int(most_recent_entry['date'])).replace(tzinfo=pytz.utc).astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "            most_recent_date = date.strftime('%Y-%m-%d')\n",
    "            most_recent_tvl = most_recent_entry['tvl']\n",
    "            \n",
    "            # Return the most recent date and its TVL\n",
    "            return {most_recent_date: most_recent_tvl}\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dex_vol(chain_name:str):\n",
    "    \"\"\"\n",
    "    Get aggregate dex volume done on each chain aggregated across all dexes\n",
    "    \"\"\"\n",
    "    dex_volume = {'24H': 0, '7D': 0, '30D': 0}\n",
    "    dex_url = f\"https://api.llama.fi/overview/dexs/{chain_name}?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyVolume\"\n",
    "\n",
    "    try:\n",
    "        dex_data = requests.get(dex_url).json()\n",
    "        for entry in dex_data['protocols']:\n",
    "            dex_volume['24H'] += round(entry.get('total24h', 0),2) if entry.get('total24h') is  not None else 0 \n",
    "            dex_volume['7D'] += round(entry.get('total7d', 0),2) if entry.get('total7d') is  not None else 0 \n",
    "            dex_volume['30D'] += round(entry.get('total30d', 0),3) if entry.get('total30d') is  not None else 0 \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return dex_volume\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect back to the SQL databse with historical data, and update the most recent dates data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_exists(chain_name, date, table_name):\n",
    "    conn = sqlite3.connect('../chain_data.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = f\"SELECT EXISTS(SELECT 1 FROM {table_name} WHERE chain_name=? AND date=? LIMIT 1)\"\n",
    "    cursor.execute(query, (chain_name, date))\n",
    "    exists = cursor.fetchone()[0]\n",
    "    \n",
    "    conn.close()\n",
    "    return exists == 1\n",
    "\n",
    "def insert_data(table_name, data_dict):\n",
    "    \"\"\"\n",
    "    Insert data into the specified table.\n",
    "    \n",
    "    Parameters:\n",
    "    - table_name: The name of the table to insert data into.\n",
    "    - data_dict: A dictionary where keys are column names and values are the data to insert.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect('../chain_data.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Prepare column names and placeholders for values\n",
    "    columns = ', '.join(data_dict.keys())\n",
    "    placeholders = ', '.join(['?' for _ in data_dict])\n",
    "    \n",
    "    query = f'''INSERT OR REPLACE INTO {table_name} ({columns}) VALUES ({placeholders})'''\n",
    "    cursor.execute(query, list(data_dict.values()))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_insert_flows(chain_name):\n",
    "    # Use the modified get_net_flows function that focuses on the most recent data\n",
    "    flows_data = get_most_recent_net_flows(chain_name)\n",
    "    for date, net_inflow in flows_data.items():\n",
    "        if not entry_exists(chain_name, date, 'net_flows'):\n",
    "            insert_data('net_flows', {\n",
    "                'chain_name': chain_name,\n",
    "                'date': date,\n",
    "                'net_inflow': net_inflow\n",
    "            })\n",
    "\n",
    "def fetch_and_insert_stablecoins(chain_name):\n",
    "    # Use the modified get_stables function\n",
    "    stables_data = get_most_recent_stables(chain_name)\n",
    "    for date, total_stables in stables_data.items():\n",
    "        if not entry_exists(chain_name, date, 'Stablecoins'):\n",
    "            insert_data('Stablecoins', {\n",
    "                'chain_name': chain_name,\n",
    "                'date': date,\n",
    "                'total_stables': total_stables\n",
    "            })\n",
    "\n",
    "def fetch_and_insert_tvl(chain_name):\n",
    "    # Use the modified get_tvl function\n",
    "    tvl_data = get_most_recent_tvl(chain_name)\n",
    "    for date, tvl in tvl_data.items():\n",
    "        if not entry_exists(chain_name, date, 'TVL'):\n",
    "            insert_data('TVL', {\n",
    "                'chain_name': chain_name,\n",
    "                'date': date,\n",
    "                'TVL': tvl\n",
    "            })\n",
    "\n",
    "def fetch_and_insert_dex_volume(chain_name):\n",
    "    dex_volume_data = get_dex_vol(chain_name)  # Ensure this function returns the most recent 24H, 7D, and 30D volume data\n",
    "    # Prepare the data dictionary for insertion\n",
    "    formatted_dex_volume_data = {\n",
    "        'chain_name': chain_name,\n",
    "        'volume_24h': dex_volume_data.get('24H', 0),\n",
    "        'volume_7d': dex_volume_data.get('7D', 0),\n",
    "        'volume_30d': dex_volume_data.get('30D', 0),\n",
    "    }\n",
    "    # Directly insert or replace the DEX volume data for the chain\n",
    "    insert_data('Dex_Volume', formatted_dex_volume_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: type NoneType doesn't define __round__ method\n",
      "An error occurred: type NoneType doesn't define __round__ method\n"
     ]
    }
   ],
   "source": [
    "chains = ['Ethereum', 'Solana', 'Base', 'Sei', 'Sui', 'Injective', 'Avalanche', 'Optimism']\n",
    "\n",
    "for chain in chains:\n",
    "    fetch_and_insert_flows(chain)\n",
    "    fetch_and_insert_stablecoins(chain)\n",
    "    fetch_and_insert_tvl(chain)\n",
    "    fetch_and_insert_dex_volume(chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "- Calculate % changes and stuff by chain for each data point by pulling from SQL\n",
    "- Find a way to present it pretty like slurpxbt\n",
    "- Find a way to automate the data pull + addition to db and email sending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
